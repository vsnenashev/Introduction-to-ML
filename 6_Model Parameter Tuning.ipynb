{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49e42b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from math import floor, exp, sqrt, pi, cos, sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7021e526",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Getting requirements to build wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [15 lines of output]\n",
      "  The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  rather than 'sklearn' for pip commands.\n",
      "  \n",
      "  Here is how to fix this error in the main use cases:\n",
      "  - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "    (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  - if the 'sklearn' package is used by one of your dependencies,\n",
      "    it would be great if you take some time to track which package uses\n",
      "    'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  - as a last resort, set the environment variable\n",
      "    SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \n",
      "  More information is available at\n",
      "  https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "Getting requirements to build wheel did not run successfully.\n",
      "exit code: 1\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a8a62b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f3a03c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_to_2(x):\n",
    "   \n",
    "    return round(x, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e364ebb7",
   "metadata": {},
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7e0114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(model, x_val, y_val):\n",
    "    \"\"\"\n",
    "    Estimates model accuracy using the \"mean deviation from prediction\" metric.\n",
    "    \n",
    "    Arguments:\n",
    "        model: The model.\n",
    "        x_test: Test set objects.\n",
    "        y_test: Predicted values for the test set.\n",
    "            \n",
    "    Returns:\n",
    "        Model accuracy.\n",
    "    \"\"\"\n",
    "    \n",
    "    y_pred = model.predict(x_val)\n",
    "    \n",
    "    res = 0\n",
    "\n",
    "    for i in range(len(y_val)):\n",
    "        res += abs(y_pred[i] - y_val[i])\n",
    "        \n",
    "    return res / len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "625aa87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_solution(model, \n",
    "                         model_configs,\n",
    "                         x_train, y_train, \n",
    "                         x_val, y_val):\n",
    "    \"\"\"\n",
    "    Finds the best linear regression model configuration using grid search.\n",
    "    \n",
    "    Arguments:\n",
    "        model: The model.\n",
    "        model_configs: List of configurations.\n",
    "        x_train: Training set objects.\n",
    "        y_train: Predicted values for the training set.\n",
    "        x_val: Validation set objects.\n",
    "        y_val: Predicted values for the validation set.\n",
    "            \n",
    "    Returns:\n",
    "        Best configuration and accuracy on the validation set.\n",
    "    \"\"\"\n",
    "    \n",
    "    q = []\n",
    "    \n",
    "    for config in model_configs:\n",
    "        x_train_c, x_val_c = [], []\n",
    "        \n",
    "        for el in x_train:\n",
    "            x_train_i = []\n",
    "            for j in config:\n",
    "                x_train_i.append(el[j])\n",
    "            x_train_c.append(x_train_i)\n",
    "            \n",
    "        for el in x_val:\n",
    "            x_val_i = []\n",
    "            for j in config:\n",
    "                x_val_i.append(el[j])\n",
    "            x_val_c.append(x_val_i)\n",
    "            \n",
    "        model.fit(x_train_c, y_train)\n",
    "        q.append(round_to_2(score_model(model, x_val_c, y_val)))\n",
    "\n",
    "    qmin = min(q)\n",
    "    best_config = model_configs[q.index(qmin)]\n",
    "\n",
    "    return best_config, qmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95dc0078-3000-4b10-8418-168747031d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x_train_example = [[1, -33], [2, -21], [3, -34234]]\n",
    "data_y_train_example = [1, 2, 3]\n",
    "    \n",
    "data_x_val_example = [[4, -231], [5, -342341], [6, -23]]\n",
    "data_y_val_example = [4, 5, 6]\n",
    "    \n",
    "configs_example = [[0], [1]]\n",
    "    \n",
    "res_example = ([0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ecb4178-5aa4-4c0f-af6b-76a9a973e4a7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LinearRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grid_search_solution(\u001b[43mLinearRegression\u001b[49m(), configs_example, data_x_train_example, data_y_train_example, data_x_val_example, data_y_val_example)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LinearRegression' is not defined"
     ]
    }
   ],
   "source": [
    "grid_search_solution(LinearRegression(), configs_example, data_x_train_example, data_y_train_example, data_x_val_example, data_y_val_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "357cd49c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search_solution' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgrid_search_solution\u001b[49m(LinearRegression(),\n\u001b[0;32m      2\u001b[0m                                 configs_example_2,\n\u001b[0;32m      3\u001b[0m                                 data_x_train_example_2, data_y_train_example_2,\n\u001b[0;32m      4\u001b[0m                                 data_x_val_example_2, data_y_val_example_2)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grid_search_solution' is not defined"
     ]
    }
   ],
   "source": [
    "grid_search_solution(LinearRegression(),\n",
    "                                configs_example_2,\n",
    "                                data_x_train_example_2, data_y_train_example_2,\n",
    "                                data_x_val_example_2, data_y_val_example_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aacba8e",
   "metadata": {},
   "source": [
    "## Bisection Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93a680a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dichotomous_search_solution(f, a, b, eps):\n",
    "    \"\"\"\n",
    "    Finds the minimum of a given function within an interval using dichotomy.\n",
    "    \n",
    "    Arguments:\n",
    "        f: The function.\n",
    "        a: Left boundary of the interval.\n",
    "        b: Right boundary of the interval.\n",
    "        eps: Permissible error.\n",
    "            \n",
    "    Returns:\n",
    "        Coordinates of the minimum point, rounded to 2 decimal places.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    while abs(a - b) > 2 * eps:\n",
    "        an, bn = (a + b - eps) / 2, (a + b + eps) / 2\n",
    "        if f(an) > f(bn):\n",
    "            a, b = an, b\n",
    "        else:\n",
    "            a, b = a, bn\n",
    "\n",
    "    return round_to_2((a + b) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d0a83400-f5ec-4db3-a65a-75719b31de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_example = lambda x: x ** 2\n",
    "    \n",
    "a_example = -2\n",
    "b_example = 5\n",
    "eps_example = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b9709c0-6280-4f68-ac0b-9493cf338ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dichotomous_search_solution(f_example, a_example, b_example, eps_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b65f9ac",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee277984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_solution(grad_f, x_0, alpha, eps):\n",
    "    \"\"\"\n",
    "    Finds the minimum of a given two-variable function using gradient descent.\n",
    "    \n",
    "    Arguments:\n",
    "        grad_f: The gradient function.\n",
    "        x_0: Starting point.\n",
    "        alpha: Learning rate coefficient.\n",
    "        eps: Minimum distance between points.\n",
    "            \n",
    "    Returns:\n",
    "        Minimum point coordinates, rounded to 2 decimal places.\n",
    "    \"\"\"\n",
    "    \n",
    "    def dist_v(x1, x2):\n",
    "        return ((x1[0] - x2[0]) ** 2 + (x1[1] - x2[1]) ** 2) ** (1/2)\n",
    "\n",
    "    def minus_v(x1, x2):\n",
    "        return [(x1[0] - x2[0]), (x1[1] - x2[1])]\n",
    "\n",
    "    def coef_v(c, v):\n",
    "        return [(c * v[0]), (c * v[1])]\n",
    "\n",
    "    def v_round_to_2(v):\n",
    "        return [round_to_2(x) for x in v]\n",
    "\n",
    "    x_1 = minus_v(x_0, coef_v(alpha, grad_f(x_0)))\n",
    "\n",
    "    while dist_v(x_0, x_1) > eps:\n",
    "        x_2 = minus_v(x_1, coef_v(alpha, grad_f(x_1)))\n",
    "        x_0, x_1 = x_1, x_2\n",
    "\n",
    "    return v_round_to_2(x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "33458af4-1ed1-446b-b7b5-b3f75ae57071",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_example = lambda x: 2 * x[0] ** 2 + 2 * x[1] ** 2\n",
    "grad_f_example = lambda x: [4 * x[0], 4 * x[1]]\n",
    "    \n",
    "x_0_example = [32, -4]\n",
    "    \n",
    "alpha_example = 0.01\n",
    "eps_example = 0.001\n",
    "    \n",
    "res_example = [0.02, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7cbca3bd-6740-45bb-a431-1a424b9aa4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02, -0.0]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent_solution(grad_f_example, x_0_example, alpha_example, eps_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e68b85",
   "metadata": {},
   "source": [
    "## Simulated Annealing Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "28a7759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x):\n",
    "    return 2 * x ** 2 + cos(pi * x) - 2.9 * sin(2 * pi * x) + cos(3 * pi * x) * sin(pi * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18fe0d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_with_p(random_gen, p, new_x, x):\n",
    "    \"\"\"\n",
    "    Returns `new_x` with probability p, otherwise returns x.\n",
    "    \n",
    "    Arguments:\n",
    "        random_gen: Random number generator.\n",
    "        p: Probability of returning new_x.\n",
    "        new_x: Point returned with probability p.\n",
    "        x: Point returned otherwise.\n",
    "            \n",
    "    Returns:\n",
    "        Point according to probability p.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    val = random_gen.random()\n",
    "    \n",
    "    if val > p:\n",
    "        return x\n",
    "    \n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16e88d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_annealing_solution(f, x_0, t_0, lam, eps, random_gen):\n",
    "    \"\"\"\n",
    "    Uses simulated annealing to find a function's minimum.\n",
    "    \n",
    "    Args:\n",
    "        f: The function to minimize.\n",
    "        x_0: Starting point.\n",
    "        t_0: Initial temperature.\n",
    "        lam: Cooling coefficient.\n",
    "        eps: Stopping temperature.\n",
    "        random_gen: Random number generator.\n",
    "    \n",
    "    Returns:\n",
    "        The point estimated as the function's minimum.\n",
    "    \"\"\"\n",
    "    \n",
    "    while t_0 > eps:\n",
    "        dx = random_gen.uniform(-1, 1)\n",
    "        new_x = x_0 + dx\n",
    "        df = f(new_x) - f(x_0)\n",
    "        if df <= 0:\n",
    "            x_0 = new_x\n",
    "        else:\n",
    "            p = exp(-df / t_0)\n",
    "            x_0 = sub_with_p(random_gen, p, new_x, x_0)\n",
    "        t_0 *= lam\n",
    "\n",
    "    return round_to_2(x_0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d8b021a5-02d5-43ed-bfb1-6c28ca448a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = 1000\n",
    "t_1 = 1000\n",
    "lam1 = 0.999\n",
    "eps1 = 0.0001\n",
    "random_gen1 = random.Random(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7cbc448d-5a0d-42bf-9ca6-c5059306dacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.1387666385411794"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g(simulated_annealing_solution(g, x_1, t_1, lam1, eps1, random_gen1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
